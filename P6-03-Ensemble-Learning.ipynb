{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28627936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Damien\\anaconda3\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.4.0, the latest is 0.5.0.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "import cv2\n",
    "from PIL import Image as Image_PIL\n",
    "from os import listdir\n",
    "from matplotlib.image import imread\n",
    "import time\n",
    "from random import sample\n",
    "from sklearn import manifold, decomposition, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1b772",
   "metadata": {},
   "source": [
    "### Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb28a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\Damien\\Desktop\\Data Scientist\\P6\\Dataset\\df_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812862f1",
   "metadata": {},
   "source": [
    "#### Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc8b883",
   "metadata": {},
   "source": [
    "**NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462f1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a8ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(train['cat_lvl_1'])\n",
    "y_test = encoder.fit_transform(test['cat_lvl_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48482b2a",
   "metadata": {},
   "source": [
    "**Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6998b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svd_tfidf = make_pipeline(CountVectorizer(),\n",
    "                               TfidfTransformer(),\n",
    "                               TruncatedSVD(n_components=300))\n",
    "pipe_svd_tfidf.fit(train['desc_clean'])\n",
    "feat_train_svd_tfidf = pipe_svd_tfidf.transform(train['desc_clean'])\n",
    "feat_test_svd_tfidf = pipe_svd_tfidf.transform(test['desc_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb259af",
   "metadata": {},
   "source": [
    "**IMG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a2ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path_list, size):\n",
    "    liste_image = []\n",
    "    compteur = 0\n",
    "    for image in path_list:\n",
    "        im = Image_PIL.open(image).resize((size, size))\n",
    "        im2 = np.array(im)/255\n",
    "        liste_image.append(im2)\n",
    "        compteur += 1\n",
    "\n",
    "    del compteur\n",
    "    del im\n",
    "    del im2\n",
    "\n",
    "    return liste_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4ccdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Damien/Desktop/Data Scientist/P6/Dataset/Flipkart/Images512/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e73de2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-0ff9aa097a5a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['image'] = train['image'].apply(lambda x: path+str(x))\n",
      "<ipython-input-8-0ff9aa097a5a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['image'] = test['image'].apply(lambda x: path+str(x))\n"
     ]
    }
   ],
   "source": [
    "train['image'] = train['image'].apply(lambda x: path+str(x))\n",
    "test['image'] = test['image'].apply(lambda x: path+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa53beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_IMG = get_files(train['image'], size=224)\n",
    "X_test_IMG = get_files(test['image'], size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4aed850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_IMG = tf.stack(X_train_IMG)\n",
    "y_train_IMG = tf.stack(y_train)\n",
    "\n",
    "X_test_IMG = tf.stack(X_test_IMG)\n",
    "y_test_IMG = tf.stack(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17933365",
   "metadata": {},
   "source": [
    "**Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb8be284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b2977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger VGG16 sans couches de classification (include_top=False)\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False,\n",
    "                  input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf8776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in VGG_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "702570f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_IMG_train = VGG_model.predict(X_train_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8082afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_img_train = features_IMG_train.reshape(\n",
    "    features_IMG_train.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40ffb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_IMG_test = VGG_model.predict(X_test_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ebb4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_img_test = features_IMG_test.reshape(features_IMG_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710f4b13",
   "metadata": {},
   "source": [
    "#### Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa70e5",
   "metadata": {},
   "source": [
    "**NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a10e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nlp = LogisticRegression()\n",
    "clf_nlp.fit(feat_train_svd_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06c8e2",
   "metadata": {},
   "source": [
    "**IMG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58d752bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_img = RandomForestClassifier()\n",
    "clf_img.fit(features_img_train, y_train_IMG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6193382",
   "metadata": {},
   "source": [
    "#### Voting Classifier \"à la main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ea00acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = [features_img_train, feat_train_svd_tfidf]\n",
    "X_test_list = [features_img_test, feat_test_svd_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63492802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_multiple_estimators(classifiers, X_list, y, sample_weights=None):\n",
    "\n",
    "    # Fit all estimators with their respective feature arrays\n",
    "    estimators_ = [clf.fit(X, y) if sample_weights is None else clf.fit(\n",
    "        X, y, sample_weights) for clf, X in zip([clf for _, clf in classifiers], X_list)]\n",
    "\n",
    "    return estimators_  # , le_\n",
    "\n",
    "\n",
    "def predict_from_multiple_estimator(estimators, label_encoder, X_list, weights=None):\n",
    "\n",
    "    # Predict 'soft' voting with probabilities\n",
    "\n",
    "    pred1 = [clf.predict_proba(X) for clf, X in zip(estimators, X_list)]\n",
    "    pred2 = np.average(pred1, axis=0, weights=weights)\n",
    "    pred = np.argmax(pred2, axis=1)\n",
    "\n",
    "    # Convert integer predictions to original labels:\n",
    "    return label_encoder.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55bab9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the number of estimators here are equal to number of different feature datas\n",
    "classifiers = [('TL',  clf_img),\n",
    "               ('TFIDF', clf_nlp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7dbc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = clf_img.predict_proba(features_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cbd0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nlp = clf_nlp.predict_proba(feat_test_svd_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d4e4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clf = [pred_img, pred_nlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ecc5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_soft = np.average(pred_clf, axis=0, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc622a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(pred_soft, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "244f54b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 2, 1, 6, 0, 3, 2, 4, 4, 6, 4, 5, 1, 2, 2, 0, 2, 4, 4, 5, 2,\n",
       "       0, 2, 6, 1, 3, 5, 1, 5, 5, 2, 2, 6, 3, 4, 6, 3, 3, 2, 4, 1, 5, 4,\n",
       "       1, 5, 3, 2, 0, 4, 5, 3, 5, 4, 2, 0, 1, 5, 2, 4, 4, 3, 6, 5, 6, 0,\n",
       "       0, 3, 4, 6, 0, 2, 2, 2, 6, 2, 4, 3, 2, 4, 3, 4, 2, 5, 2, 6, 4, 3,\n",
       "       3, 3, 4, 4, 5, 3, 6, 2, 0, 6, 3, 0, 4, 6, 3, 4, 2, 6, 1, 5, 4, 2,\n",
       "       5, 4, 4, 0, 4, 1, 2, 6, 6, 2, 2, 2, 3, 4, 5, 3, 1, 3, 0, 0, 5, 1,\n",
       "       3, 3, 0, 5, 3, 1, 5, 2, 5, 0, 3, 4, 4, 6, 6, 1, 3, 1, 6, 1, 6, 3,\n",
       "       2, 4, 6, 1, 3, 6, 6, 6, 0, 2, 3, 6, 6, 2, 6, 2, 6, 1, 4, 6, 0, 6,\n",
       "       3, 3, 4, 3, 0, 5, 4, 3, 0, 1, 0, 6, 2, 4, 1, 6, 5, 4, 5, 2, 1, 5,\n",
       "       2, 2, 1, 0, 4, 2, 1, 3, 6, 0, 0, 3, 6, 2, 2, 2, 4, 1, 0, 4, 3, 3,\n",
       "       4, 3, 0, 4, 2, 3, 4, 0, 2, 1, 2, 2, 1, 2, 5, 4, 0, 6, 1, 4, 4, 4,\n",
       "       4, 0, 3, 2, 3, 3, 4, 5, 0, 6, 5, 0, 3, 0, 5, 3, 1, 0, 0, 6, 6],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ee30f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy sur jeu train :  0.9505703422053232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('accuracy sur jeu train : ',\n",
    "      accuracy_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1020c5",
   "metadata": {},
   "source": [
    "#### Voting Classifier avec Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cedc44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(787, 25088)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e1c2b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 25088)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_img_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b638616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(787, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train_svd_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dd39096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_test_svd_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e97415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.concatenate(\n",
    "    (features_img_train, feat_train_svd_tfidf), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bee11415",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.concatenate(\n",
    "    (features_img_test, feat_test_svd_tfidf), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ea58f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(787, 25388)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82d5279a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 25388)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fcac107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "######################\n",
    "# custom transformer for sklearn pipeline\n",
    "\n",
    "\n",
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def transform(self, X):\n",
    "        col_list = []\n",
    "        for c in self.cols:\n",
    "            col_list.append(X[:, c:c+1])\n",
    "        return np.concatenate(col_list, axis=1)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c6491a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7756653992395437"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit clf_img with f1\n",
    "pipe1 = Pipeline([\n",
    "    # selecting features 0 to 25088 (f1) to be used with RF (clf_img)\n",
    "    ('col_extract', ColumnExtractor(cols=range(0, 25089))),\n",
    "    ('clf', clf_img)\n",
    "])\n",
    "\n",
    "pipe1.fit(features_train, y_train)  # sanity check\n",
    "pipe1.score(features_test, y_test)  # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b1fc7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9467680608365019"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit clf_nlp with f2\n",
    "pipe2 = Pipeline([\n",
    "    # selecting features 25089 to 25388 (f2) to be used with LR (clf_nlp)\n",
    "    ('col_extract', ColumnExtractor(cols=range(25089, 25388))),\n",
    "    ('clf', clf_nlp)\n",
    "])\n",
    "\n",
    "pipe2.fit(features_train, y_train)  # sanity check\n",
    "pipe2.score(features_test, y_test)  # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83dbd448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9315589353612167"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voting classifier where clf1 fitted with df1 and clf2 fitted with df2\n",
    "eclf = VotingClassifier(estimators=[(\n",
    "    'f1-clf_img', pipe1), ('f2-clf_nlp', pipe2)], voting='soft', weights=[1, 1])\n",
    "eclf.fit(features_train, y_train)\n",
    "eclf.score(features_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a59ebc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136882129277566"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble/voting classifier where clf1 fitted with df1 and clf2 fitted with df2\n",
    "eclf = VotingClassifier(estimators=[(\n",
    "    'f1-clf_img', pipe1), ('f2-clf_nlp', pipe2)], voting='hard', weights=[1, 1])\n",
    "eclf.fit(features_train, y_train)\n",
    "eclf.score(features_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
